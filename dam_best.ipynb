{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import numpy as np\n",
    "import math\n",
    "from lightly.data import LightlyDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "\n",
    "from my_dino_components_best import My_DINOLoss\n",
    "from lightly.models.modules import DINOProjectionHead\n",
    "from lightly.models.utils import deactivate_requires_grad, update_momentum\n",
    "from lightly.utils.scheduler import cosine_schedule\n",
    "from iqa_distortions_best import Transform_Global_WD\n",
    "\n",
    "from torch.nn.utils import clip_grad_value_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=3407\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic=True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "num_workers=50\n",
    "input_size = 224\n",
    "out_dim = 256\n",
    "detype = 'alt'\n",
    "level = 5\n",
    "margin = 1.0\n",
    "tri_type = 'tri'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"//home//lt//my_complex_sector_240301//\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightly.data._image_loaders import pil_loader\n",
    "if pil_loader(path_to_data+os.listdir(path_to_data)[0]).mode != 'RGB':\n",
    "    raise ValueError(\"Wrong channel!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DINO(torch.nn.Module):\n",
    "    def __init__(self, backbone, input_dim):\n",
    "        super().__init__()\n",
    "        self.student_backbone = backbone\n",
    "        self.student_head = DINOProjectionHead(\n",
    "            input_dim, 512, 64, out_dim, freeze_last_layer=1\n",
    "        )\n",
    "        self.teacher_backbone = copy.deepcopy(backbone)\n",
    "        self.teacher_head = DINOProjectionHead(input_dim, 512, 64, out_dim)\n",
    "        deactivate_requires_grad(self.teacher_backbone)\n",
    "        deactivate_requires_grad(self.teacher_head)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.student_backbone(x).flatten(start_dim=1)\n",
    "        z = self.student_head(y)\n",
    "        return z\n",
    "\n",
    "    def forward_teacher(self, x):\n",
    "        y = self.teacher_backbone(x).flatten(start_dim=1)\n",
    "        z = self.teacher_head(y)\n",
    "        return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DINO(\n",
       "  (student_backbone): ResNet(\n",
       "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (student_head): DINOProjectionHead(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "      (4): Linear(in_features=512, out_features=64, bias=True)\n",
       "    )\n",
       "    (last_layer): Linear(in_features=64, out_features=256, bias=False)\n",
       "  )\n",
       "  (teacher_backbone): ResNet(\n",
       "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (teacher_head): DINOProjectionHead(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "      (4): Linear(in_features=512, out_features=64, bias=True)\n",
       "    )\n",
       "    (last_layer): Linear(in_features=64, out_features=256, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone =  timm.create_model('resnet18', pretrained = False,in_chans = 1)\n",
    "hidden_dim = backbone.fc.in_features\n",
    "backbone.reset_classifier(0)\n",
    "temp_model = DINO(backbone, hidden_dim)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "temp_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Transform_Global_WD(level = level,detype = detype)\n",
    "dataset_train = LightlyDataset(input_dir=path_to_data, transform=transform)\n",
    "dataloader_train = torch.utils.data.DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_clip_grad_value_(parameters, clip_value):\n",
    "    if isinstance(parameters, torch.Tensor):\n",
    "        parameters = [parameters]\n",
    "    clip_value = float(clip_value)\n",
    "    for p in filter(lambda p: p.grad is not None, parameters):\n",
    "        p.grad.data.clamp_(min=-clip_value, max=clip_value)\n",
    "        p.grad.data = p.grad.data.nan_to_num(nan=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level: 5 epoch: 00, loss: 13.74884\n",
      "level: 5 epoch: 01, loss: 12.38223\n",
      "level: 5 epoch: 02, loss: 8.71642\n",
      "level: 5 epoch: 03, loss: 6.27088\n",
      "level: 5 epoch: 04, loss: 4.52726\n",
      "level: 5 epoch: 05, loss: 3.05764\n",
      "level: 5 epoch: 06, loss: 2.05166\n",
      "level: 5 epoch: 07, loss: 1.33708\n",
      "level: 5 epoch: 08, loss: 0.93956\n",
      "level: 5 epoch: 09, loss: 0.72083\n",
      "level: 5 epoch: 10, loss: 0.42041\n",
      "level: 5 epoch: 11, loss: 0.28374\n",
      "level: 5 epoch: 12, loss: 0.20895\n",
      "level: 5 epoch: 13, loss: 0.22952\n",
      "level: 5 epoch: 14, loss: 0.15959\n",
      "level: 5 epoch: 15, loss: 0.15340\n",
      "level: 5 epoch: 16, loss: 0.13845\n",
      "level: 5 epoch: 17, loss: 0.12644\n",
      "level: 5 epoch: 18, loss: 0.08482\n",
      "level: 5 epoch: 19, loss: 0.10641\n",
      "level: 5 epoch: 20, loss: 0.07852\n",
      "level: 5 epoch: 21, loss: 0.15067\n",
      "level: 5 epoch: 22, loss: 0.07923\n",
      "level: 5 epoch: 23, loss: 0.07334\n",
      "level: 5 epoch: 24, loss: 0.07524\n",
      "level: 5 epoch: 25, loss: 0.10780\n",
      "level: 5 epoch: 26, loss: 0.05676\n",
      "level: 5 epoch: 27, loss: 0.05139\n",
      "level: 5 epoch: 28, loss: 0.03888\n",
      "level: 5 epoch: 29, loss: 0.05742\n",
      "level: 5 epoch: 30, loss: 0.02663\n",
      "level: 5 epoch: 31, loss: 0.05017\n",
      "level: 5 epoch: 32, loss: 0.08545\n",
      "level: 5 epoch: 33, loss: 0.02930\n",
      "level: 5 epoch: 34, loss: 0.01126\n",
      "level: 5 epoch: 35, loss: 0.07566\n",
      "level: 5 epoch: 36, loss: 0.04587\n",
      "level: 5 epoch: 37, loss: 0.01956\n",
      "level: 5 epoch: 38, loss: 0.06080\n",
      "level: 5 epoch: 39, loss: 0.01596\n",
      "level: 5 epoch: 40, loss: 0.05009\n",
      "level: 5 epoch: 41, loss: 0.02270\n",
      "level: 5 epoch: 42, loss: 0.05098\n",
      "level: 5 epoch: 43, loss: 0.01240\n",
      "level: 5 epoch: 44, loss: 0.02199\n",
      "level: 5 epoch: 45, loss: 0.06473\n",
      "level: 5 epoch: 46, loss: 0.01605\n",
      "level: 5 epoch: 47, loss: 0.00429\n",
      "level: 5 epoch: 48, loss: 0.02254\n",
      "level: 5 epoch: 49, loss: 0.04894\n",
      "level: 5 epoch: 50, loss: 0.02787\n",
      "level: 5 epoch: 51, loss: 0.02105\n",
      "level: 5 epoch: 52, loss: 0.02085\n",
      "level: 5 epoch: 53, loss: 0.01770\n",
      "level: 5 epoch: 54, loss: 0.03066\n",
      "level: 5 epoch: 55, loss: 0.01670\n",
      "level: 5 epoch: 56, loss: 0.01554\n",
      "level: 5 epoch: 57, loss: 0.04192\n",
      "level: 5 epoch: 58, loss: 0.02882\n",
      "level: 5 epoch: 59, loss: 0.00295\n",
      "level: 5 epoch: 60, loss: 0.00117\n",
      "level: 5 epoch: 61, loss: 0.02654\n",
      "level: 5 epoch: 62, loss: 0.03492\n",
      "level: 5 epoch: 63, loss: 0.00687\n",
      "level: 5 epoch: 64, loss: 0.05812\n",
      "level: 5 epoch: 65, loss: 0.01469\n",
      "level: 5 epoch: 66, loss: 0.01518\n",
      "level: 5 epoch: 67, loss: 0.00800\n",
      "level: 5 epoch: 68, loss: 0.00702\n",
      "level: 5 epoch: 69, loss: 0.00329\n",
      "level: 5 epoch: 70, loss: 0.00539\n",
      "level: 5 epoch: 71, loss: 0.00870\n",
      "level: 5 epoch: 72, loss: 0.01922\n",
      "level: 5 epoch: 73, loss: 0.00187\n",
      "level: 5 epoch: 74, loss: 0.02304\n",
      "level: 5 epoch: 75, loss: 0.00067\n",
      "level: 5 epoch: 76, loss: 0.00205\n",
      "level: 5 epoch: 77, loss: 0.00259\n",
      "level: 5 epoch: 78, loss: 0.00446\n",
      "level: 5 epoch: 79, loss: 0.00338\n",
      "level: 5 epoch: 80, loss: 0.00056\n",
      "level: 5 epoch: 81, loss: 0.00551\n",
      "level: 5 epoch: 82, loss: 0.02031\n",
      "level: 5 epoch: 83, loss: 0.01147\n",
      "level: 5 epoch: 84, loss: 0.00000\n",
      "level: 5 epoch: 85, loss: 0.00029\n",
      "level: 5 epoch: 86, loss: 0.00249\n",
      "level: 5 epoch: 87, loss: 0.01250\n",
      "level: 5 epoch: 88, loss: 0.00378\n",
      "level: 5 epoch: 89, loss: 0.00467\n",
      "level: 5 epoch: 90, loss: 0.02135\n",
      "level: 5 epoch: 91, loss: 0.00236\n",
      "level: 5 epoch: 92, loss: 0.00051\n",
      "level: 5 epoch: 93, loss: 0.00000\n",
      "level: 5 epoch: 94, loss: 0.00000\n",
      "level: 5 epoch: 95, loss: 0.01481\n",
      "level: 5 epoch: 96, loss: 0.00686\n",
      "level: 5 epoch: 97, loss: 0.00000\n",
      "level: 5 epoch: 98, loss: 0.00000\n",
      "level: 5 epoch: 99, loss: 0.00000\n",
      "level: 5 epoch: 100, loss: 0.00377\n",
      "level: 5 epoch: 101, loss: 0.00000\n",
      "level: 5 epoch: 102, loss: 0.00000\n",
      "level: 5 epoch: 103, loss: 0.00046\n",
      "level: 5 epoch: 104, loss: 0.00000\n",
      "level: 5 epoch: 105, loss: 0.00001\n",
      "level: 5 epoch: 106, loss: 0.00025\n",
      "level: 5 epoch: 107, loss: 0.00023\n",
      "level: 5 epoch: 108, loss: 0.00000\n",
      "level: 5 epoch: 109, loss: 0.00000\n",
      "level: 5 epoch: 110, loss: 0.00000\n",
      "level: 5 epoch: 111, loss: 0.00000\n",
      "level: 5 epoch: 112, loss: 0.00000\n",
      "level: 5 epoch: 113, loss: 0.00000\n",
      "level: 5 epoch: 114, loss: 0.00000\n",
      "level: 5 epoch: 115, loss: 0.00000\n",
      "level: 5 epoch: 116, loss: 0.00000\n",
      "level: 5 epoch: 117, loss: 0.00000\n",
      "level: 5 epoch: 118, loss: 0.00005\n",
      "level: 5 epoch: 119, loss: 0.00000\n",
      "level: 4 epoch: 00, loss: 0.00023\n",
      "level: 4 epoch: 01, loss: 0.00024\n",
      "level: 4 epoch: 02, loss: 0.00261\n",
      "level: 4 epoch: 03, loss: 0.00572\n",
      "level: 4 epoch: 04, loss: 0.00253\n",
      "level: 4 epoch: 05, loss: 0.04236\n",
      "level: 4 epoch: 06, loss: 0.01348\n",
      "level: 4 epoch: 07, loss: 0.01191\n",
      "level: 4 epoch: 08, loss: 0.03191\n",
      "level: 4 epoch: 09, loss: 0.02123\n",
      "level: 4 epoch: 10, loss: 0.01245\n",
      "level: 4 epoch: 11, loss: 0.02165\n",
      "level: 4 epoch: 12, loss: 0.05451\n",
      "level: 4 epoch: 13, loss: 0.02117\n",
      "level: 4 epoch: 14, loss: 0.02225\n",
      "level: 4 epoch: 15, loss: 0.03069\n",
      "level: 4 epoch: 16, loss: 0.10440\n",
      "level: 4 epoch: 17, loss: 0.03880\n",
      "level: 4 epoch: 18, loss: 0.00061\n",
      "level: 4 epoch: 19, loss: 0.01593\n",
      "level: 4 epoch: 20, loss: 0.08377\n",
      "level: 4 epoch: 21, loss: 0.07108\n",
      "level: 4 epoch: 22, loss: 0.02213\n",
      "level: 4 epoch: 23, loss: 0.00356\n",
      "level: 4 epoch: 24, loss: 0.03310\n",
      "level: 4 epoch: 25, loss: 0.01125\n",
      "level: 4 epoch: 26, loss: 0.03404\n",
      "level: 4 epoch: 27, loss: 0.01181\n",
      "level: 4 epoch: 28, loss: 0.03882\n",
      "level: 4 epoch: 29, loss: 0.01800\n",
      "level: 4 epoch: 30, loss: 0.00072\n",
      "level: 4 epoch: 31, loss: 0.01992\n",
      "level: 4 epoch: 32, loss: 0.09654\n",
      "level: 4 epoch: 33, loss: 0.02410\n",
      "level: 4 epoch: 34, loss: 0.00001\n",
      "level: 4 epoch: 35, loss: 0.00456\n",
      "level: 4 epoch: 36, loss: 0.00254\n",
      "level: 4 epoch: 37, loss: 0.00000\n",
      "level: 4 epoch: 38, loss: 0.00000\n",
      "level: 4 epoch: 39, loss: 0.00000\n",
      "level: 4 epoch: 40, loss: 0.00000\n",
      "level: 4 epoch: 41, loss: 0.06549\n",
      "level: 4 epoch: 42, loss: 0.00292\n",
      "level: 4 epoch: 43, loss: 0.01944\n",
      "level: 4 epoch: 44, loss: 0.01086\n",
      "level: 4 epoch: 45, loss: 0.00683\n",
      "level: 4 epoch: 46, loss: 0.00338\n",
      "level: 4 epoch: 47, loss: 0.00214\n",
      "level: 4 epoch: 48, loss: 0.00733\n",
      "level: 4 epoch: 49, loss: 0.01395\n",
      "level: 4 epoch: 50, loss: 0.01899\n",
      "level: 4 epoch: 51, loss: 0.01427\n",
      "level: 4 epoch: 52, loss: 0.00643\n",
      "level: 4 epoch: 53, loss: 0.00443\n",
      "level: 4 epoch: 54, loss: 0.00084\n",
      "level: 4 epoch: 55, loss: 0.00039\n",
      "level: 4 epoch: 56, loss: 0.03877\n",
      "level: 4 epoch: 57, loss: 0.03763\n",
      "level: 4 epoch: 58, loss: 0.01323\n",
      "level: 4 epoch: 59, loss: 0.00377\n",
      "level: 4 epoch: 60, loss: 0.00317\n",
      "level: 4 epoch: 61, loss: 0.00064\n",
      "level: 4 epoch: 62, loss: 0.00102\n",
      "level: 4 epoch: 63, loss: 0.00363\n",
      "level: 4 epoch: 64, loss: 0.01490\n",
      "level: 4 epoch: 65, loss: 0.00240\n",
      "level: 4 epoch: 66, loss: 0.00061\n",
      "level: 4 epoch: 67, loss: 0.01701\n",
      "level: 4 epoch: 68, loss: 0.00910\n",
      "level: 4 epoch: 69, loss: 0.00570\n",
      "level: 4 epoch: 70, loss: 0.00095\n",
      "level: 4 epoch: 71, loss: 0.00662\n",
      "level: 4 epoch: 72, loss: 0.00386\n",
      "level: 4 epoch: 73, loss: 0.00067\n",
      "level: 4 epoch: 74, loss: 0.00266\n",
      "level: 4 epoch: 75, loss: 0.00145\n",
      "level: 4 epoch: 76, loss: 0.00139\n",
      "level: 4 epoch: 77, loss: 0.00002\n",
      "level: 4 epoch: 78, loss: 0.00704\n",
      "level: 4 epoch: 79, loss: 0.00065\n",
      "level: 4 epoch: 80, loss: 0.00121\n",
      "level: 4 epoch: 81, loss: 0.00369\n",
      "level: 4 epoch: 82, loss: 0.00000\n",
      "level: 4 epoch: 83, loss: 0.00269\n",
      "level: 4 epoch: 84, loss: 0.00397\n",
      "level: 4 epoch: 85, loss: 0.00000\n",
      "level: 4 epoch: 86, loss: 0.00006\n",
      "level: 4 epoch: 87, loss: 0.00046\n",
      "level: 4 epoch: 88, loss: 0.00052\n",
      "level: 4 epoch: 89, loss: 0.00016\n",
      "level: 4 epoch: 90, loss: 0.00025\n",
      "level: 4 epoch: 91, loss: 0.00000\n",
      "level: 4 epoch: 92, loss: 0.00000\n",
      "level: 4 epoch: 93, loss: 0.00000\n",
      "level: 4 epoch: 94, loss: 0.00000\n",
      "level: 4 epoch: 95, loss: 0.00000\n",
      "level: 4 epoch: 96, loss: 0.00000\n",
      "level: 4 epoch: 97, loss: 0.00000\n",
      "level: 4 epoch: 98, loss: 0.00000\n",
      "level: 4 epoch: 99, loss: 0.00000\n",
      "level: 4 epoch: 100, loss: 0.00023\n",
      "level: 4 epoch: 101, loss: 0.00014\n",
      "level: 4 epoch: 102, loss: 0.00480\n",
      "level: 4 epoch: 103, loss: 0.00000\n",
      "level: 4 epoch: 104, loss: 0.00000\n",
      "level: 4 epoch: 105, loss: 0.00562\n",
      "level: 4 epoch: 106, loss: 0.00000\n",
      "level: 4 epoch: 107, loss: 0.00000\n",
      "level: 4 epoch: 108, loss: 0.00000\n",
      "level: 4 epoch: 109, loss: 0.00000\n",
      "level: 4 epoch: 110, loss: 0.00019\n",
      "level: 4 epoch: 111, loss: 0.00004\n",
      "level: 4 epoch: 112, loss: 0.00000\n",
      "level: 4 epoch: 113, loss: 0.00000\n",
      "level: 4 epoch: 114, loss: 0.00000\n",
      "level: 4 epoch: 115, loss: 0.00036\n",
      "level: 4 epoch: 116, loss: 0.00563\n",
      "level: 4 epoch: 117, loss: 0.00000\n",
      "level: 4 epoch: 118, loss: 0.00000\n",
      "level: 4 epoch: 119, loss: 0.00000\n",
      "level: 3 epoch: 00, loss: 0.00090\n",
      "level: 3 epoch: 01, loss: 0.00240\n",
      "level: 3 epoch: 02, loss: 0.00251\n",
      "level: 3 epoch: 03, loss: 0.00569\n",
      "level: 3 epoch: 04, loss: 0.00352\n",
      "level: 3 epoch: 05, loss: 0.00892\n",
      "level: 3 epoch: 06, loss: 0.00505\n",
      "level: 3 epoch: 07, loss: 0.01218\n",
      "level: 3 epoch: 08, loss: 0.01923\n",
      "level: 3 epoch: 09, loss: 0.02791\n",
      "level: 3 epoch: 10, loss: 0.01991\n",
      "level: 3 epoch: 11, loss: 0.01475\n",
      "level: 3 epoch: 12, loss: 0.00301\n",
      "level: 3 epoch: 13, loss: 0.01637\n",
      "level: 3 epoch: 14, loss: 0.00240\n",
      "level: 3 epoch: 15, loss: 0.02748\n",
      "level: 3 epoch: 16, loss: 0.05631\n",
      "level: 3 epoch: 17, loss: 0.02110\n",
      "level: 3 epoch: 18, loss: 0.00542\n",
      "level: 3 epoch: 19, loss: 0.05562\n",
      "level: 3 epoch: 20, loss: 0.03794\n",
      "level: 3 epoch: 21, loss: 0.01181\n",
      "level: 3 epoch: 22, loss: 0.01813\n",
      "level: 3 epoch: 23, loss: 0.05006\n",
      "level: 3 epoch: 24, loss: 0.02484\n",
      "level: 3 epoch: 25, loss: 0.02105\n",
      "level: 3 epoch: 26, loss: 0.01986\n",
      "level: 3 epoch: 27, loss: 0.01407\n",
      "level: 3 epoch: 28, loss: 0.01620\n",
      "level: 3 epoch: 29, loss: 0.06146\n",
      "level: 3 epoch: 30, loss: 0.01609\n",
      "level: 3 epoch: 31, loss: 0.02443\n",
      "level: 3 epoch: 32, loss: 0.01060\n",
      "level: 3 epoch: 33, loss: 0.02683\n",
      "level: 3 epoch: 34, loss: 0.01403\n",
      "level: 3 epoch: 35, loss: 0.01903\n",
      "level: 3 epoch: 36, loss: 0.00869\n",
      "level: 3 epoch: 37, loss: 0.01672\n",
      "level: 3 epoch: 38, loss: 0.01185\n",
      "level: 3 epoch: 39, loss: 0.12134\n",
      "level: 3 epoch: 40, loss: 0.03288\n",
      "level: 3 epoch: 41, loss: 0.00321\n",
      "level: 3 epoch: 42, loss: 0.01503\n",
      "level: 3 epoch: 43, loss: 0.00573\n",
      "level: 3 epoch: 44, loss: 0.00921\n",
      "level: 3 epoch: 45, loss: 0.02349\n",
      "level: 3 epoch: 46, loss: 0.00326\n",
      "level: 3 epoch: 47, loss: 0.00619\n",
      "level: 3 epoch: 48, loss: 0.00817\n",
      "level: 3 epoch: 49, loss: 0.02056\n",
      "level: 3 epoch: 50, loss: 0.00241\n",
      "level: 3 epoch: 51, loss: 0.00377\n",
      "level: 3 epoch: 52, loss: 0.01691\n",
      "level: 3 epoch: 53, loss: 0.00056\n",
      "level: 3 epoch: 54, loss: 0.02451\n",
      "level: 3 epoch: 55, loss: 0.01185\n",
      "level: 3 epoch: 56, loss: 0.01338\n",
      "level: 3 epoch: 57, loss: 0.01004\n",
      "level: 3 epoch: 58, loss: 0.00099\n",
      "level: 3 epoch: 59, loss: 0.03990\n",
      "level: 3 epoch: 60, loss: 0.00119\n",
      "level: 3 epoch: 61, loss: 0.00584\n",
      "level: 3 epoch: 62, loss: 0.00971\n",
      "level: 3 epoch: 63, loss: 0.00455\n",
      "level: 3 epoch: 64, loss: 0.02335\n",
      "level: 3 epoch: 65, loss: 0.01174\n",
      "level: 3 epoch: 66, loss: 0.00436\n",
      "level: 3 epoch: 67, loss: 0.01384\n",
      "level: 3 epoch: 68, loss: 0.00076\n",
      "level: 3 epoch: 69, loss: 0.00029\n",
      "level: 3 epoch: 70, loss: 0.00010\n",
      "level: 3 epoch: 71, loss: 0.00635\n",
      "level: 3 epoch: 72, loss: 0.01104\n",
      "level: 3 epoch: 73, loss: 0.00272\n",
      "level: 3 epoch: 74, loss: 0.00817\n",
      "level: 3 epoch: 75, loss: 0.00470\n",
      "level: 3 epoch: 76, loss: 0.01137\n",
      "level: 3 epoch: 77, loss: 0.01367\n",
      "level: 3 epoch: 78, loss: 0.01241\n",
      "level: 3 epoch: 79, loss: 0.00347\n",
      "level: 3 epoch: 80, loss: 0.02069\n",
      "level: 3 epoch: 81, loss: 0.00397\n",
      "level: 3 epoch: 82, loss: 0.00335\n",
      "level: 3 epoch: 83, loss: 0.00875\n",
      "level: 3 epoch: 84, loss: 0.00017\n",
      "level: 3 epoch: 85, loss: 0.00826\n",
      "level: 3 epoch: 86, loss: 0.00828\n",
      "level: 3 epoch: 87, loss: 0.00299\n",
      "level: 3 epoch: 88, loss: 0.00475\n",
      "level: 3 epoch: 89, loss: 0.00131\n",
      "level: 3 epoch: 90, loss: 0.00109\n",
      "level: 3 epoch: 91, loss: 0.00258\n",
      "level: 3 epoch: 92, loss: 0.00211\n",
      "level: 3 epoch: 93, loss: 0.00022\n",
      "level: 3 epoch: 94, loss: 0.00047\n",
      "level: 3 epoch: 95, loss: 0.00030\n",
      "level: 3 epoch: 96, loss: 0.00225\n",
      "level: 3 epoch: 97, loss: 0.00182\n",
      "level: 3 epoch: 98, loss: 0.01320\n",
      "level: 3 epoch: 99, loss: 0.00067\n",
      "level: 3 epoch: 100, loss: 0.00060\n",
      "level: 3 epoch: 101, loss: 0.00007\n",
      "level: 3 epoch: 102, loss: 0.01368\n",
      "level: 3 epoch: 103, loss: 0.00331\n",
      "level: 3 epoch: 104, loss: 0.00290\n",
      "level: 3 epoch: 105, loss: 0.00000\n",
      "level: 3 epoch: 106, loss: 0.00000\n",
      "level: 3 epoch: 107, loss: 0.00028\n",
      "level: 3 epoch: 108, loss: 0.00068\n",
      "level: 3 epoch: 109, loss: 0.00000\n",
      "level: 3 epoch: 110, loss: 0.00000\n",
      "level: 3 epoch: 111, loss: 0.00450\n",
      "level: 3 epoch: 112, loss: 0.00000\n",
      "level: 3 epoch: 113, loss: 0.00000\n",
      "level: 3 epoch: 114, loss: 0.00054\n",
      "level: 3 epoch: 115, loss: 0.00030\n",
      "level: 3 epoch: 116, loss: 0.00137\n",
      "level: 3 epoch: 117, loss: 0.00000\n",
      "level: 3 epoch: 118, loss: 0.00024\n",
      "level: 3 epoch: 119, loss: 0.00002\n",
      "level: 2 epoch: 00, loss: 0.02367\n",
      "level: 2 epoch: 01, loss: 0.02743\n",
      "level: 2 epoch: 02, loss: 0.00566\n",
      "level: 2 epoch: 03, loss: 0.01170\n",
      "level: 2 epoch: 04, loss: 0.00089\n",
      "level: 2 epoch: 05, loss: 0.00478\n",
      "level: 2 epoch: 06, loss: 0.02979\n",
      "level: 2 epoch: 07, loss: 0.02013\n",
      "level: 2 epoch: 08, loss: 0.03843\n",
      "level: 2 epoch: 09, loss: 0.04064\n",
      "level: 2 epoch: 10, loss: 0.01781\n",
      "level: 2 epoch: 11, loss: 0.00644\n",
      "level: 2 epoch: 12, loss: 0.03365\n",
      "level: 2 epoch: 13, loss: 0.03394\n",
      "level: 2 epoch: 14, loss: 0.03049\n",
      "level: 2 epoch: 15, loss: 0.00777\n",
      "level: 2 epoch: 16, loss: 0.01848\n",
      "level: 2 epoch: 17, loss: 0.04687\n",
      "level: 2 epoch: 18, loss: 0.03095\n",
      "level: 2 epoch: 19, loss: 0.03098\n",
      "level: 2 epoch: 20, loss: 0.04068\n",
      "level: 2 epoch: 21, loss: 0.03622\n",
      "level: 2 epoch: 22, loss: 0.05606\n",
      "level: 2 epoch: 23, loss: 0.05321\n",
      "level: 2 epoch: 24, loss: 0.07261\n",
      "level: 2 epoch: 25, loss: 0.06125\n",
      "level: 2 epoch: 26, loss: 0.04245\n",
      "level: 2 epoch: 27, loss: 0.03589\n",
      "level: 2 epoch: 28, loss: 0.06253\n",
      "level: 2 epoch: 29, loss: 0.07182\n",
      "level: 2 epoch: 30, loss: 0.01373\n",
      "level: 2 epoch: 31, loss: 0.04894\n",
      "level: 2 epoch: 32, loss: 0.03061\n",
      "level: 2 epoch: 33, loss: 0.02387\n",
      "level: 2 epoch: 34, loss: 0.02427\n",
      "level: 2 epoch: 35, loss: 0.02700\n",
      "level: 2 epoch: 36, loss: 0.01367\n",
      "level: 2 epoch: 37, loss: 0.06660\n",
      "level: 2 epoch: 38, loss: 0.13448\n",
      "level: 2 epoch: 39, loss: 0.03540\n",
      "level: 2 epoch: 40, loss: 0.06705\n",
      "level: 2 epoch: 41, loss: 0.02555\n",
      "level: 2 epoch: 42, loss: 0.02649\n",
      "level: 2 epoch: 43, loss: 0.03954\n",
      "level: 2 epoch: 44, loss: 0.03872\n",
      "level: 2 epoch: 45, loss: 0.02721\n",
      "level: 2 epoch: 46, loss: 0.05965\n",
      "level: 2 epoch: 47, loss: 0.01918\n",
      "level: 2 epoch: 48, loss: 0.02419\n",
      "level: 2 epoch: 49, loss: 0.02025\n",
      "level: 2 epoch: 50, loss: 0.04521\n",
      "level: 2 epoch: 51, loss: 0.01530\n",
      "level: 2 epoch: 52, loss: 0.03534\n",
      "level: 2 epoch: 53, loss: 0.01343\n",
      "level: 2 epoch: 54, loss: 0.04547\n",
      "level: 2 epoch: 55, loss: 0.01519\n",
      "level: 2 epoch: 56, loss: 0.00978\n",
      "level: 2 epoch: 57, loss: 0.01637\n",
      "level: 2 epoch: 58, loss: 0.03645\n",
      "level: 2 epoch: 59, loss: 0.00978\n",
      "level: 2 epoch: 60, loss: 0.01881\n",
      "level: 2 epoch: 61, loss: 0.01108\n",
      "level: 2 epoch: 62, loss: 0.01732\n",
      "level: 2 epoch: 63, loss: 0.00944\n",
      "level: 2 epoch: 64, loss: 0.01807\n",
      "level: 2 epoch: 65, loss: 0.00332\n",
      "level: 2 epoch: 66, loss: 0.00850\n",
      "level: 2 epoch: 67, loss: 0.01342\n",
      "level: 2 epoch: 68, loss: 0.03374\n",
      "level: 2 epoch: 69, loss: 0.06357\n",
      "level: 2 epoch: 70, loss: 0.01249\n",
      "level: 2 epoch: 71, loss: 0.06132\n",
      "level: 2 epoch: 72, loss: 0.00368\n",
      "level: 2 epoch: 73, loss: 0.01572\n",
      "level: 2 epoch: 74, loss: 0.01799\n",
      "level: 2 epoch: 75, loss: 0.03144\n",
      "level: 2 epoch: 76, loss: 0.00216\n",
      "level: 2 epoch: 77, loss: 0.03520\n",
      "level: 2 epoch: 78, loss: 0.01728\n",
      "level: 2 epoch: 79, loss: 0.01337\n",
      "level: 2 epoch: 80, loss: 0.00039\n",
      "level: 2 epoch: 81, loss: 0.00224\n",
      "level: 2 epoch: 82, loss: 0.00604\n",
      "level: 2 epoch: 83, loss: 0.00085\n",
      "level: 2 epoch: 84, loss: 0.05034\n",
      "level: 2 epoch: 85, loss: 0.02747\n",
      "level: 2 epoch: 86, loss: 0.01746\n",
      "level: 2 epoch: 87, loss: 0.00288\n",
      "level: 2 epoch: 88, loss: 0.02110\n",
      "level: 2 epoch: 89, loss: 0.00208\n",
      "level: 2 epoch: 90, loss: 0.01347\n",
      "level: 2 epoch: 91, loss: 0.00557\n",
      "level: 2 epoch: 92, loss: 0.00033\n",
      "level: 2 epoch: 93, loss: 0.00120\n",
      "level: 2 epoch: 94, loss: 0.00059\n",
      "level: 2 epoch: 95, loss: 0.00666\n",
      "level: 2 epoch: 96, loss: 0.00068\n",
      "level: 2 epoch: 97, loss: 0.00438\n",
      "level: 2 epoch: 98, loss: 0.00094\n",
      "level: 2 epoch: 99, loss: 0.00409\n",
      "level: 2 epoch: 100, loss: 0.00262\n",
      "level: 2 epoch: 101, loss: 0.01653\n",
      "level: 2 epoch: 102, loss: 0.01652\n",
      "level: 2 epoch: 103, loss: 0.00065\n",
      "level: 2 epoch: 104, loss: 0.00405\n",
      "level: 2 epoch: 105, loss: 0.00189\n",
      "level: 2 epoch: 106, loss: 0.00000\n",
      "level: 2 epoch: 107, loss: 0.00262\n",
      "level: 2 epoch: 108, loss: 0.00122\n",
      "level: 2 epoch: 109, loss: 0.00007\n",
      "level: 2 epoch: 110, loss: 0.00309\n",
      "level: 2 epoch: 111, loss: 0.00301\n",
      "level: 2 epoch: 112, loss: 0.00361\n",
      "level: 2 epoch: 113, loss: 0.00101\n",
      "level: 2 epoch: 114, loss: 0.00000\n",
      "level: 2 epoch: 115, loss: 0.00875\n",
      "level: 2 epoch: 116, loss: 0.00014\n",
      "level: 2 epoch: 117, loss: 0.00284\n",
      "level: 2 epoch: 118, loss: 0.00434\n",
      "level: 2 epoch: 119, loss: 0.00106\n",
      "level: 1 epoch: 00, loss: 0.02422\n",
      "level: 1 epoch: 01, loss: 0.04463\n",
      "level: 1 epoch: 02, loss: 0.02286\n",
      "level: 1 epoch: 03, loss: 0.05708\n",
      "level: 1 epoch: 04, loss: 0.05716\n",
      "level: 1 epoch: 05, loss: 0.02328\n",
      "level: 1 epoch: 06, loss: 0.02171\n",
      "level: 1 epoch: 07, loss: 0.05161\n",
      "level: 1 epoch: 08, loss: 0.04359\n",
      "level: 1 epoch: 09, loss: 0.11359\n",
      "level: 1 epoch: 10, loss: 0.05524\n",
      "level: 1 epoch: 11, loss: 0.08302\n",
      "level: 1 epoch: 12, loss: 0.02503\n",
      "level: 1 epoch: 13, loss: 0.16474\n",
      "level: 1 epoch: 14, loss: 0.04445\n",
      "level: 1 epoch: 15, loss: 0.05430\n",
      "level: 1 epoch: 16, loss: 0.12796\n",
      "level: 1 epoch: 17, loss: 0.06225\n",
      "level: 1 epoch: 18, loss: 0.08294\n",
      "level: 1 epoch: 19, loss: 0.05854\n",
      "level: 1 epoch: 20, loss: 0.08072\n",
      "level: 1 epoch: 21, loss: 0.09108\n",
      "level: 1 epoch: 22, loss: 0.14516\n",
      "level: 1 epoch: 23, loss: 0.06820\n",
      "level: 1 epoch: 24, loss: 0.06373\n",
      "level: 1 epoch: 25, loss: 0.11292\n",
      "level: 1 epoch: 26, loss: 0.12338\n",
      "level: 1 epoch: 27, loss: 0.10369\n",
      "level: 1 epoch: 28, loss: 0.15102\n",
      "level: 1 epoch: 29, loss: 0.07692\n",
      "level: 1 epoch: 30, loss: 0.13368\n",
      "level: 1 epoch: 31, loss: 0.05600\n",
      "level: 1 epoch: 32, loss: 0.04086\n",
      "level: 1 epoch: 33, loss: 0.08868\n",
      "level: 1 epoch: 34, loss: 0.13143\n",
      "level: 1 epoch: 35, loss: 0.10510\n",
      "level: 1 epoch: 36, loss: 0.08177\n",
      "level: 1 epoch: 37, loss: 0.05903\n",
      "level: 1 epoch: 38, loss: 0.05784\n",
      "level: 1 epoch: 39, loss: 0.09821\n",
      "level: 1 epoch: 40, loss: 0.18547\n",
      "level: 1 epoch: 41, loss: 0.09603\n",
      "level: 1 epoch: 42, loss: 0.07132\n",
      "level: 1 epoch: 43, loss: 0.04828\n",
      "level: 1 epoch: 44, loss: 0.10017\n",
      "level: 1 epoch: 45, loss: 0.09966\n",
      "level: 1 epoch: 46, loss: 0.06990\n",
      "level: 1 epoch: 47, loss: 0.06937\n",
      "level: 1 epoch: 48, loss: 0.03997\n",
      "level: 1 epoch: 49, loss: 0.10854\n",
      "level: 1 epoch: 50, loss: 0.07012\n",
      "level: 1 epoch: 51, loss: 0.13470\n",
      "level: 1 epoch: 52, loss: 0.01213\n",
      "level: 1 epoch: 53, loss: 0.04804\n",
      "level: 1 epoch: 54, loss: 0.06059\n",
      "level: 1 epoch: 55, loss: 0.03333\n",
      "level: 1 epoch: 56, loss: 0.03015\n",
      "level: 1 epoch: 57, loss: 0.04331\n",
      "level: 1 epoch: 58, loss: 0.04247\n",
      "level: 1 epoch: 59, loss: 0.01245\n",
      "level: 1 epoch: 60, loss: 0.05165\n",
      "level: 1 epoch: 61, loss: 0.00448\n",
      "level: 1 epoch: 62, loss: 0.03520\n",
      "level: 1 epoch: 63, loss: 0.10072\n",
      "level: 1 epoch: 64, loss: 0.05518\n",
      "level: 1 epoch: 65, loss: 0.04825\n",
      "level: 1 epoch: 66, loss: 0.03542\n",
      "level: 1 epoch: 67, loss: 0.04683\n",
      "level: 1 epoch: 68, loss: 0.04510\n",
      "level: 1 epoch: 69, loss: 0.07604\n",
      "level: 1 epoch: 70, loss: 0.07045\n",
      "level: 1 epoch: 71, loss: 0.02683\n",
      "level: 1 epoch: 72, loss: 0.04426\n",
      "level: 1 epoch: 73, loss: 0.02386\n",
      "level: 1 epoch: 74, loss: 0.06945\n",
      "level: 1 epoch: 75, loss: 0.03778\n",
      "level: 1 epoch: 76, loss: 0.07006\n",
      "level: 1 epoch: 77, loss: 0.01363\n",
      "level: 1 epoch: 78, loss: 0.05203\n",
      "level: 1 epoch: 79, loss: 0.07136\n",
      "level: 1 epoch: 80, loss: 0.01372\n",
      "level: 1 epoch: 81, loss: 0.03663\n",
      "level: 1 epoch: 82, loss: 0.03935\n",
      "level: 1 epoch: 83, loss: 0.03766\n",
      "level: 1 epoch: 84, loss: 0.00663\n",
      "level: 1 epoch: 85, loss: 0.00351\n",
      "level: 1 epoch: 86, loss: 0.00002\n",
      "level: 1 epoch: 87, loss: 0.00430\n",
      "level: 1 epoch: 88, loss: 0.00541\n",
      "level: 1 epoch: 89, loss: 0.03951\n",
      "level: 1 epoch: 90, loss: 0.04869\n",
      "level: 1 epoch: 91, loss: 0.03669\n",
      "level: 1 epoch: 92, loss: 0.02524\n",
      "level: 1 epoch: 93, loss: 0.03051\n",
      "level: 1 epoch: 94, loss: 0.07126\n",
      "level: 1 epoch: 95, loss: 0.05966\n",
      "level: 1 epoch: 96, loss: 0.01104\n",
      "level: 1 epoch: 97, loss: 0.01477\n",
      "level: 1 epoch: 98, loss: 0.01963\n",
      "level: 1 epoch: 99, loss: 0.05353\n",
      "level: 1 epoch: 100, loss: 0.03495\n",
      "level: 1 epoch: 101, loss: 0.01175\n",
      "level: 1 epoch: 102, loss: 0.01687\n",
      "level: 1 epoch: 103, loss: 0.03746\n",
      "level: 1 epoch: 104, loss: 0.00306\n",
      "level: 1 epoch: 105, loss: 0.02592\n",
      "level: 1 epoch: 106, loss: 0.01483\n",
      "level: 1 epoch: 107, loss: 0.02241\n",
      "level: 1 epoch: 108, loss: 0.02792\n",
      "level: 1 epoch: 109, loss: 0.01376\n",
      "level: 1 epoch: 110, loss: 0.00909\n",
      "level: 1 epoch: 111, loss: 0.01869\n",
      "level: 1 epoch: 112, loss: 0.02092\n",
      "level: 1 epoch: 113, loss: 0.00215\n",
      "level: 1 epoch: 114, loss: 0.00649\n",
      "level: 1 epoch: 115, loss: 0.01704\n",
      "level: 1 epoch: 116, loss: 0.03324\n",
      "level: 1 epoch: 117, loss: 0.01847\n",
      "level: 1 epoch: 118, loss: 0.02871\n",
      "level: 1 epoch: 119, loss: 0.00584\n"
     ]
    }
   ],
   "source": [
    "level_range = 5\n",
    "for level_i in range(level_range):\n",
    "    level = level_range-level_i\n",
    "    transform = Transform_Global_WD(level = level,detype = detype)\n",
    "    dataset_train = LightlyDataset(input_dir=path_to_data, transform=transform)\n",
    "    dataloader_train = torch.utils.data.DataLoader(\n",
    "        dataset_train,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        num_workers=num_workers,\n",
    "    ) \n",
    "    epochs = 120\n",
    "    criterion = My_DINOLoss(device = device,output_dim=out_dim,tri_type = tri_type,margin = margin)\n",
    "    optim = torch.optim.Adam(temp_model.parameters(), lr=0.0001, weight_decay=0.05)\n",
    "    lambda_w_warm = lambda epoch: (epoch / 20) if epoch < 20 else 0.5 * (math.cos((epoch - 20)/(100) * math.pi) + 1)\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optim, lr_lambda=lambda_w_warm)\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        momentum_val = 0.999\n",
    "        for batch in dataloader_train:\n",
    "            views = batch[0]\n",
    "            update_momentum(temp_model.student_backbone, temp_model.teacher_backbone, m=momentum_val)\n",
    "            update_momentum(temp_model.student_head, temp_model.teacher_head, m=momentum_val)\n",
    "            views = [view.to(device) for view in views]\n",
    "            raw_views = views[0:1]\n",
    "            nonde_views = views[1:2]\n",
    "            de_views = views[2:3]\n",
    "            teacher_out = [temp_model.forward_teacher(view) for view in raw_views] \n",
    "            student_nonde_out = [temp_model.forward(view) for view in nonde_views]\n",
    "            student_de_out = [temp_model.forward(view) for view in de_views]\n",
    "            # print(teacher_out[0].shape,student_out[0].shape)\n",
    "\n",
    "            # teacher_out.to(device)\n",
    "            # student_out.to(device)\n",
    "            loss = criterion(teacher_out, student_nonde_out, student_de_out, epoch=epoch)\n",
    "            total_loss += loss.detach()\n",
    "            loss.backward()\n",
    "            # We only cancel gradients of student head.\n",
    "            temp_model.student_head.cancel_last_layer_gradients(current_epoch=epoch)\n",
    "            my_clip_grad_value_(temp_model.parameters(),2.0)\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "        avg_loss = total_loss / len(dataloader_train)\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"level: {level:>01} epoch: {epoch:>02}, loss: {avg_loss:.5f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
